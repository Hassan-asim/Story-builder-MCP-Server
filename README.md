# MCP APP - Choose Your Own Adventure AI ğŸ®ğŸ“š

A sophisticated, full-stack interactive storytelling application that leverages AI to create personalized adventure stories. Built with modern web technologies and integrated with the Model Context Protocol (MCP) for seamless natural language interactions through Gemini CLI.

## ğŸ¥ Demo Video

**ğŸ“¹ Watch the Complete Demo** - Comprehensive walkthrough of the application features, MCP integration, and natural language interactions.

### ğŸ¬ Watch the Demo Video

[![Watch Demo Video](https://img.shields.io/badge/ğŸ¥-Watch%20Demo%20Video-blue?style=for-the-badge&logo=video)](./MCP_app_recording.mp4)

**Click the button above to download and watch the demo video**

### ğŸ“± Alternative Video Hosting Options:

#### Option 1: Loom (Recommended)
- Go to [Loom.com](https://loom.com)
- Upload your `MCP_app_recording.mp4`
- Get a shareable link
- Replace the button link above

#### Option 2: Vimeo
- Go to [Vimeo.com](https://vimeo.com)
- Upload your video
- Get embed link
- Update the button above

#### Option 3: Google Drive
- Upload to Google Drive
- Set sharing to "Anyone with link can view"
- Copy the shareable link
- Update the button above

#### Option 4: Dropbox
- Upload to Dropbox
- Create a shareable link
- Update the button above

### ğŸ“¥ Direct Download
- **File**: [MCP_app_recording.mp4](./MCP_app_recording.mp4)
- **Size**: ~61 MB
- **Format**: MP4 (compatible with all devices)

### ğŸ¯ What's Included in the Demo:
- âœ… **Story Creation**: Theme-based story generation
- âœ… **Interactive Gameplay**: Making choices and story progression  
- âœ… **MCP Integration**: Natural language commands through Gemini CLI
- âœ… **Frontend Interface**: React components and user experience
- âœ… **Backend API**: FastAPI endpoints and job processing
- âœ… **Real-time Updates**: Job status monitoring and story loading

### ğŸ’¡ Quick Setup Instructions:
1. Choose one of the hosting options above
2. Upload your `MCP_app_recording.mp4` file
3. Get the shareable/embed link
4. Replace `./MCP_app_recording.mp4` in the button above with your new link
5. Commit and push the changes

*Note: These platforms provide better viewing experience than direct download and work well on GitHub.*

## ğŸŒŸ Key Features

### ğŸ¯ Core Functionality
- **ğŸ§  AI-Powered Story Generation**: Uses OpenAI's GPT models to create engaging, creative narratives
- **ğŸ® Interactive Storytelling**: Make choices that dynamically affect story direction and outcomes
- **ğŸ¨ Theme-Based Creation**: Generate stories from any theme (space adventure, medieval fantasy, detective mystery, etc.)
- **âš¡ Real-time Processing**: Asynchronous story generation with comprehensive job status tracking
- **ğŸ’¾ Persistent Storage**: SQLite database for story persistence and retrieval
- **ğŸ”„ State Management**: Maintains game state across sessions with session tracking

### ğŸ¤– Advanced MCP Integration
- **ğŸ—£ï¸ Natural Language Interface**: Interact with the app using conversational commands through Gemini CLI
- **ğŸ”§ FastMCP Server**: Custom MCP server exposing comprehensive app functionality as callable tools
- **ğŸŒ‰ Seamless Bridge**: Intelligent translation between natural language and FastAPI backend
- **ğŸ“Š State Tracking**: Maintains game state across MCP interactions
- **ğŸ¯ Context Awareness**: Remembers current story position and available options

## ğŸ”„ Application Flow

```mermaid
flowchart TD
    A[User Input Theme] --> B[Frontend: StoryGenerator]
    B --> C[API: POST /stories/create]
    C --> D[Backend: Story Creation Job]
    D --> E[OpenAI: Generate Story]
    E --> F[Database: Save Story Structure]
    F --> G[Job Status: Completed]
    G --> H[Frontend: StoryGame Component]
    H --> I[User Makes Choice]
    I --> J[API: POST /stories/choice]
    J --> K[Backend: Process Choice]
    K --> L[OpenAI: Continue Story]
    L --> M[Database: Update Story]
    M --> N[Return Next Story Segment]
    N --> H
    
    %% MCP Integration Flow
    O[Gemini CLI] --> P[MCP Server]
    P --> Q[Natural Language Processing]
    Q --> R[MCP Tools]
    R --> S[create_story]
    R --> T[check_job_status]
    R --> U[get_story]
    R --> V[make_choice]
    R --> W[get_current_status]
    R --> X[list_available_options]
    
    S --> C
    T --> Y[Job Status Response]
    U --> Z[Story Data Response]
    V --> J
    W --> AA[Current Game State]
    X --> BB[Available Choices]
    
    %% Styling
    classDef frontend fill:#e1f5fe
    classDef backend fill:#f3e5f5
    classDef database fill:#e8f5e8
    classDef mcp fill:#fff3e0
    classDef ai fill:#fce4ec
    
    class A,B,H frontend
    class C,D,G,J,K,M,N backend
    class F database
    class O,P,Q,R,S,T,U,V,W,X mcp
    class E,L ai
```

## ğŸ—ï¸ Technical Architecture

### ğŸ“± Frontend Stack (React + Vite)
```
frontend/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”œâ”€â”€ StoryGenerator.jsx    # Theme input and story creation interface
â”‚   â”‚   â”œâ”€â”€ StoryGame.jsx         # Interactive story display and choice handling
â”‚   â”‚   â”œâ”€â”€ StoryLoader.jsx       # Story loading, navigation, and history
â”‚   â”‚   â”œâ”€â”€ LoadingStatus.jsx     # Real-time job status monitoring
â”‚   â”‚   â””â”€â”€ ThemeInput.jsx        # Enhanced theme input component
â”‚   â”œâ”€â”€ App.jsx                   # Main application component
â”‚   â”œâ”€â”€ util.js                   # API configuration and utilities
â”‚   â”œâ”€â”€ App.css                   # Application styling
â”‚   â””â”€â”€ index.css                 # Global styles
â”œâ”€â”€ public/
â”‚   â””â”€â”€ vite.svg                  # Vite branding
â”œâ”€â”€ package.json                  # Dependencies and scripts
â”œâ”€â”€ vite.config.js               # Vite configuration
â””â”€â”€ eslint.config.js             # ESLint configuration
```

**Frontend Technologies:**
- **React 19.1.0**: Latest React with concurrent features
- **Vite 6.3.5**: Fast build tool and development server
- **React Router DOM 7.6.0**: Client-side routing
- **Axios 1.9.0**: HTTP client for API communication
- **ESLint**: Code quality and consistency

### âš™ï¸ Backend Stack (FastAPI + SQLite)
```
backend/
â”œâ”€â”€ main.py                       # FastAPI application entry point
â”œâ”€â”€ mcp_server.py                 # Comprehensive MCP server implementation
â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ config.py                 # Application configuration and settings
â”‚   â”œâ”€â”€ models.py                 # SQLAlchemy database models
â”‚   â”œâ”€â”€ prompts.py                # AI prompts for story generation
â”‚   â””â”€â”€ story_generator.py        # OpenAI integration and story logic
â”œâ”€â”€ routers/
â”‚   â”œâ”€â”€ story.py                  # Story-related API endpoints
â”‚   â””â”€â”€ job.py                    # Job status and management endpoints
â”œâ”€â”€ db/
â”‚   â””â”€â”€ database.py               # Database connection and table creation
â”œâ”€â”€ schemas/
â”‚   â”œâ”€â”€ story.py                  # Pydantic schemas for story validation
â”‚   â””â”€â”€ job.py                    # Pydantic schemas for job validation
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ story.py                  # Story data models
â”‚   â””â”€â”€ job.py                    # Job data models
â”œâ”€â”€ pyproject.toml                # Python project configuration
â”œâ”€â”€ requirements.txt              # Python dependencies
â”œâ”€â”€ uv.lock                       # UV lock file for dependency management
â””â”€â”€ run_mcp_server.sh            # MCP server startup script
```

**Backend Technologies:**
- **FastAPI 0.115.12+**: Modern, fast web framework with automatic API documentation
- **SQLAlchemy 2.0.41+**: Advanced ORM for database operations
- **LangChain 0.3.25+**: Framework for LLM applications
- **LangChain OpenAI 0.3.18+**: OpenAI integration for LangChain
- **Uvicorn 0.34.2+**: ASGI server for FastAPI
- **Python-dotenv 1.1.0+**: Environment variable management
- **Pydantic**: Data validation and serialization

## ğŸš€ Installation & Setup

### ğŸ“‹ Prerequisites
- **Python 3.13+** (as specified in pyproject.toml)
- **Node.js 16+** (for frontend development)
- **OpenAI API Key** (for story generation)
- **Git** (for version control)

### ğŸ”§ Installation Steps

1. **Clone the Repository**
   ```bash
   git clone <your-repository-url>
   cd MCP\ APP
   ```

2. **Backend Setup**
   ```bash
   cd backend
   
   # Create virtual environment
   python -m venv venv
   
   # Activate virtual environment
   # Windows:
   venv\Scripts\activate
   # macOS/Linux:
   source venv/bin/activate
   
   # Install dependencies using pip or uv
   pip install -r requirements.txt
   # OR if using uv:
   uv pip install -r requirements.txt
   ```

3. **Environment Configuration**
   ```bash
   # Create .env file in backend directory
   cat > .env << EOF
   DATABASE_URL=sqlite:///./databse.db
   API_PREFIX=/api
   DEBUG=True
   ALLOWED_ORIGINS=http://localhost:3000,http://localhost:5173,https://localhost:3000,https://localhost:5173
   OPENAI_API_KEY=your_openai_api_key_here
   EOF
   ```

4. **Frontend Setup**
   ```bash
   cd ../frontend
   npm install
   ```

### ğŸƒâ€â™‚ï¸ Running the Application

1. **Start Backend Server**
   ```bash
   cd backend
   source venv/bin/activate  # or venv\Scripts\activate on Windows
   python main.py
   ```
   - Backend available at: `http://localhost:8000`
   - API Documentation: `http://localhost:8000/docs`
   - ReDoc Documentation: `http://localhost:8000/redoc`

2. **Start Frontend Development Server**
   ```bash
   cd frontend
   npm run dev
   ```
   - Frontend available at: `http://localhost:5173`

## ğŸ¤– MCP Integration Deep Dive

### ğŸ” What is MCP?
The Model Context Protocol (MCP) is a standardized protocol for connecting AI assistants with external tools and data sources. Our implementation creates a bridge between natural language commands and the application's functionality.

### ğŸ› ï¸ MCP Server Architecture

The MCP server (`mcp_server.py`) provides:

- **State Management**: Tracks current story, node position, and session data
- **Tool Exposure**: Exposes 6 comprehensive tools for natural language interaction
- **Error Handling**: Robust error handling with detailed error messages
- **Session Persistence**: Maintains game state across interactions

### ğŸ”§ MCP Server Setup

1. **Install FastMCP**
   ```bash
   cd backend
   source venv/bin/activate
   pip install fastmcp
   ```

2. **Configure Gemini CLI**
   
   Update your `~/.gemini/settings.json`:
   ```json
   {
     "theme": "Atom One",
     "selectedAuthType": "oauth-personal",
     "mcpServers": {
       "adventure-game": {
         "command": "/path/to/MCP APP/backend/run_mcp_server.sh",
         "args": [],
         "env": {}
       }
     }
   }
   ```

3. **Make Script Executable**
   ```bash
   chmod +x backend/run_mcp_server.sh
   ```

### ğŸ› ï¸ Available MCP Tools

| Tool | Description | Parameters | Example Usage |
|------|-------------|------------|---------------|
| `create_story` | Generate new story with theme | `theme: str` | "Create a story about space pirates" |
| `check_job_status` | Check story generation progress | `job_id: Optional[str]` | "What's the status of my story?" |
| `get_story` | Retrieve complete story for gameplay | `story_id: Optional[int]` | "Load my current story" |
| `make_choice` | Make interactive story choice | `choice_text: str` | "Choose the first option" |
| `get_current_status` | Get current game state | None | "What's my current position?" |
| `list_available_options` | List all available choices | None | "What choices do I have?" |

### ğŸ’¬ Natural Language Examples

Once connected to Gemini CLI, you can use conversational commands:

**Story Creation:**
- "Create a new adventure story about space exploration"
- "Generate a mystery story set in Victorian London"
- "Make a fantasy story about dragons and magic"

**Gameplay:**
- "What's the status of my story?"
- "Load my current story"
- "What choices do I have?"
- "I want to choose the first option"
- "Choose the path that leads to the castle"

**Status Checking:**
- "What's my current position in the story?"
- "Is my story ready yet?"
- "Show me the complete story we just created"

## ğŸ› ï¸ API Reference

### ğŸ“š Story Management Endpoints

| Method | Endpoint | Description | Request Body | Response |
|--------|----------|-------------|--------------|----------|
| `POST` | `/api/stories/create` | Create new story | `{"theme": "string"}` | Job information |
| `GET` | `/api/stories/{story_id}/complete` | Get complete story | None | Full story data |
| `POST` | `/api/stories/{story_id}/choice` | Make story choice | `{"choice": "string"}` | Next story segment |

### âš™ï¸ Job Management Endpoints

| Method | Endpoint | Description | Response |
|--------|----------|-------------|----------|
| `GET` | `/api/jobs/{job_id}` | Get job status | Job status and details |

### ğŸ“Š Data Models

**Story Structure:**
```json
{
  "id": "integer",
  "title": "string",
  "theme": "string",
  "created_at": "datetime",
  "root_node": {
    "id": "integer",
    "content": "string",
    "is_ending": "boolean",
    "options": [
      {
        "text": "string",
        "next_node_id": "integer"
      }
    ]
  },
  "all_nodes": {
    "node_id": {
      "content": "string",
      "is_ending": "boolean",
      "options": "array"
    }
  }
}
```

## ğŸ¯ How It Works - Deep Dive

### ğŸ”„ Story Generation Process

1. **Theme Input**: User provides a theme (e.g., "space adventure")
2. **AI Processing**: OpenAI GPT generates initial story setup with multiple paths
3. **Database Storage**: Story structure saved to SQLite database
4. **Job Tracking**: Asynchronous job system tracks generation progress
5. **Interactive Play**: User makes choices that dynamically continue the narrative

### ğŸ§  AI Integration Details

- **Model**: Uses OpenAI's GPT models for story generation
- **Prompt Engineering**: Custom prompts ensure consistent story structure and quality
- **Narrative Coherence**: Maintains story consistency across multiple segments
- **Dynamic Branching**: Creates multiple story paths based on user choices
- **Ending Detection**: Identifies natural story conclusions

### ğŸ’¾ Database Schema

**Stories Table:**
- `id`: Primary key
- `title`: Generated story title
- `theme`: User-provided theme
- `created_at`: Timestamp
- `root_node_id`: Reference to starting node

**Story Nodes Table:**
- `id`: Primary key
- `story_id`: Foreign key to stories
- `content`: Story text content
- `is_ending`: Boolean flag for story endings
- `is_winning_ending`: Boolean flag for positive endings

**Story Options Table:**
- `id`: Primary key
- `node_id`: Foreign key to story nodes
- `text`: Choice description
- `next_node_id`: Foreign key to next node

**Jobs Table:**
- `id`: Primary key (UUID)
- `status`: Job status (pending, processing, completed, failed)
- `story_id`: Foreign key to generated story
- `theme`: Original theme
- `created_at`: Job creation timestamp
- `completed_at`: Job completion timestamp
- `error`: Error message if failed

## ğŸ”§ Configuration & Environment

### ğŸŒ Environment Variables

| Variable | Description | Default Value | Required |
|----------|-------------|---------------|----------|
| `DATABASE_URL` | SQLite database connection string | `sqlite:///./databse.db` | No |
| `API_PREFIX` | API route prefix | `/api` | No |
| `DEBUG` | Enable debug mode | `True` | No |
| `ALLOWED_ORIGINS` | CORS allowed origins | localhost variants | No |
| `OPENAI_API_KEY` | OpenAI API key for story generation | None | **Yes** |

### ğŸ”’ CORS Configuration

The backend is configured to allow requests from:
- `http://localhost:3000` (React default port)
- `http://localhost:5173` (Vite default port)
- `https://localhost:3000` (HTTPS variant)
- `https://localhost:5173` (HTTPS variant)

### ğŸ“ File Structure Overview

```
MCP APP/
â”œâ”€â”€ backend/                    # FastAPI backend
â”‚   â”œâ”€â”€ core/                  # Core application logic
â”‚   â”œâ”€â”€ db/                    # Database configuration
â”‚   â”œâ”€â”€ models/                # Data models
â”‚   â”œâ”€â”€ routers/               # API route handlers
â”‚   â”œâ”€â”€ schemas/               # Pydantic schemas
â”‚   â”œâ”€â”€ main.py                # Application entry point
â”‚   â”œâ”€â”€ mcp_server.py          # MCP server implementation
â”‚   â””â”€â”€ requirements.txt       # Python dependencies
â”œâ”€â”€ frontend/                  # React frontend
â”‚   â”œâ”€â”€ src/                   # Source code
â”‚   â”œâ”€â”€ public/                # Static assets
â”‚   â””â”€â”€ package.json           # Node.js dependencies
â”œâ”€â”€ mcp_config.json           # MCP configuration
â”œâ”€â”€ mcp_requirements.txt      # MCP-specific dependencies
â”œâ”€â”€ setup_mcp.sh              # MCP setup script
â””â”€â”€ README.md                  # This file
```

## ğŸš€ Deployment Guide

### â˜ï¸ Backend Deployment

**Production Considerations:**
- Replace SQLite with PostgreSQL for better performance and scalability
- Use environment-specific configuration files
- Implement proper logging and monitoring
- Set up reverse proxy (nginx) for production
- Use process manager (PM2, systemd) for process management

**Docker Deployment:**
```dockerfile
FROM python:3.13-slim
WORKDIR /app
COPY backend/requirements.txt .
RUN pip install -r requirements.txt
COPY backend/ .
EXPOSE 8000
CMD ["python", "main.py"]
```

### ğŸŒ Frontend Deployment

**Build Process:**
```bash
cd frontend
npm run build
```

**Deployment Options:**
- Static hosting (Netlify, Vercel, GitHub Pages)
- CDN deployment
- Container deployment with nginx

### ğŸ”§ Production Environment Variables

```bash
DATABASE_URL=postgresql://user:password@localhost:5432/adventure_db
API_PREFIX=/api
DEBUG=False
ALLOWED_ORIGINS=https://yourdomain.com,https://www.yourdomain.com
OPENAI_API_KEY=your_production_openai_key
```

## ğŸ§ª Testing

### ğŸ”¬ Backend Testing
```bash
cd backend
source venv/bin/activate
pytest tests/
```

### ğŸ¨ Frontend Testing
```bash
cd frontend
npm test
```

### ğŸ§ª MCP Testing
Test MCP integration by connecting to Gemini CLI and using natural language commands.

## ğŸ¤ Contributing

### ğŸ“ Development Workflow

1. **Fork the Repository**
   ```bash
   git clone <your-fork-url>
   cd MCP\ APP
   ```

2. **Create Feature Branch**
   ```bash
   git checkout -b feature/amazing-feature
   ```

3. **Make Changes**
   - Follow existing code style
   - Add appropriate tests
   - Update documentation

4. **Commit Changes**
   ```bash
   git commit -m 'Add amazing feature'
   ```

5. **Push and Create Pull Request**
   ```bash
   git push origin feature/amazing-feature
   ```

### ğŸ“‹ Code Standards

- **Python**: Follow PEP 8 style guide
- **JavaScript**: Use ESLint configuration
- **Documentation**: Update README for new features
- **Testing**: Add tests for new functionality
- **Type Hints**: Use type hints in Python code

## ğŸ› Troubleshooting

### Common Issues

**Backend Issues:**
- **Port 8000 already in use**: Change port in `main.py` or kill existing process
- **Database connection errors**: Check `DATABASE_URL` in `.env`
- **OpenAI API errors**: Verify `OPENAI_API_KEY` is correct and has credits

**Frontend Issues:**
- **Port 5173 already in use**: Vite will automatically use next available port
- **API connection errors**: Ensure backend is running on correct port
- **Build errors**: Clear `node_modules` and reinstall dependencies

**MCP Issues:**
- **MCP server not starting**: Check Python path in `mcp_config.json`
- **Tools not available**: Verify MCP server is running and connected
- **State not persisting**: Check MCP server logs for errors

### ğŸ” Debug Mode

Enable debug mode by setting `DEBUG=True` in your `.env` file. This provides:
- Detailed error messages
- Request/response logging
- Database query logging
- MCP server debug output

## ğŸ“š Additional Resources

### ğŸ“– Documentation Links
- [FastAPI Documentation](https://fastapi.tiangolo.com/)
- [React Documentation](https://reactjs.org/docs/)
- [Vite Documentation](https://vitejs.dev/)
- [FastMCP Documentation](https://fastmcp.com/)
- [OpenAI API Documentation](https://platform.openai.com/docs)

### ğŸ“ Learning Resources
- [Model Context Protocol Specification](https://modelcontextprotocol.io/)
- [SQLAlchemy Tutorial](https://docs.sqlalchemy.org/en/20/tutorial/)
- [React Router Guide](https://reactrouter.com/en/main)

## ğŸ“ License

**Â© 2025 Sufi Hassan Asim. All rights reserved.**

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

For inquiries, please contact: [hassanasim337@gmail.com](mailto:hassanasim337@gmail.com)

## ğŸ‘¨â€ğŸ’» Author

**Sufi Hassan Asim**
- ğŸ“§ Email: [hassanasim337@gmail.com](mailto:hassanasim337@gmail.com)
- ğŸ¯ Creator of MCP APP - Choose Your Own Adventure AI
- ğŸ“… All rights reserved Â© 2025

## ğŸ™ Acknowledgments

- **FastAPI** - Modern, fast web framework for building APIs
- **React** - JavaScript library for building user interfaces
- **Vite** - Next generation frontend tooling
- **FastMCP** - Model Context Protocol server implementation
- **OpenAI** - AI-powered story generation capabilities
- **SQLAlchemy** - Python SQL toolkit and ORM
- **LangChain** - Framework for developing LLM applications

## ğŸ“ Support & Community

### ğŸ†˜ Getting Help

1. **Check Documentation**: Review this README and inline code comments
2. **Search Issues**: Look through existing GitHub issues
3. **Create Issue**: Submit detailed bug reports or feature requests
4. **Community**: Join discussions in project forums

### ğŸ› Reporting Bugs

When reporting bugs, please include:
- **Environment**: OS, Python version, Node.js version
- **Steps to Reproduce**: Detailed steps to recreate the issue
- **Expected Behavior**: What should happen
- **Actual Behavior**: What actually happens
- **Error Messages**: Full error logs and stack traces
- **Screenshots**: Visual evidence if applicable

### ğŸ’¡ Feature Requests

For feature requests, please provide:
- **Use Case**: Why this feature would be valuable
- **Proposed Solution**: How you envision it working
- **Alternatives**: Other approaches you've considered
- **Additional Context**: Any relevant background information

---

**ğŸ­ Happy Storytelling!** âœ¨

*Built with â¤ï¸ for interactive AI storytelling*
